{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ccd57b0",
   "metadata": {},
   "source": [
    "# ü¶∑ Predicting Dental Caries Using Systemic Health Markers\n",
    "\n",
    "### Using SVM (Support Vector Machine) to classify patients with more or less probability of having dental caries\n",
    "\n",
    "This project explores the potential of **Support Vector Machine (SVM)** algorithms to predict dental caries likelihood in patients using comprehensive systemic health data. We will use a dataset from the [Kaggle Korean National Health Survey](https://www.kaggle.com/datasets/vernicacastillo/enfermedad-periodontal) that contains information about systemic health indicators and dental caries presence in patients.\n",
    "\n",
    "**Research Innovation**: This is the first study to explore correlations between liver function markers (AST, ALT, GTP) and dental caries risk - a completely novel research area with significant clinical implications.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef8b24c",
   "metadata": {},
   "source": [
    "# üéØ YOUR LEARNING JOURNEY: Step-by-Step SVM Discovery\n",
    "\n",
    "## üìö **Your Mission**\n",
    "You will discover how SVM can predict dental caries by implementing each step yourself. I'll provide guidance and help when you need it, but YOU will be the one coding and discovering the insights!\n",
    "\n",
    "## üó∫Ô∏è **Learning Roadmap**\n",
    "\n",
    "### **Phase 1: Data Exploration (YOUR TURN!)** ‚úÖ COMPLETED\n",
    "- [x] Load and explore the dataset\n",
    "- [x] Check data quality and missing values\n",
    "- [x] Understand the target variable distribution\n",
    "- [x] Calculate basic statistics for each feature category\n",
    "\n",
    "### **Phase 2: Feature Analysis (YOUR DISCOVERY!)** ‚úÖ COMPLETED\n",
    "- [x] Analyze correlations between features and dental caries\n",
    "- [x] Identify which features might be most predictive\n",
    "- [x] Explore the novel liver function markers (AST, ALT, GTP)\n",
    "- [x] Create your own feature engineering ideas\n",
    "\n",
    "### **Phase 3: SVM Implementation (YOUR CODING!)** ‚úÖ COMPLETED\n",
    "- [x] Build your first Linear SVM model\n",
    "- [x] Try RBF SVM and compare performance\n",
    "- [x] Experiment with feature engineering\n",
    "- [x] Tune hyperparameters and see what happens\n",
    "\n",
    "### **Phase 4: Model Evaluation (YOUR ANALYSIS!)** üîÑ IN PROGRESS\n",
    "- [ ] Evaluate model performance with different metrics\n",
    "- [ ] Analyze which features are most important\n",
    "- [ ] Discover novel correlations\n",
    "- [ ] Draw your own conclusions\n",
    "\n",
    "## üéì **Learning Goals**\n",
    "- Master SVM implementation from scratch\n",
    "- Discover which features matter most for caries prediction\n",
    "- Learn how to evaluate medical ML models\n",
    "- Explore the novel liver-oral health connection\n",
    "- Build confidence in your ML skills\n",
    "\n",
    "## üí° **My Role**\n",
    "- Provide guidance when you're stuck\n",
    "- Answer questions about SVM theory\n",
    "- Help debug code issues\n",
    "- Suggest next steps when you're ready\n",
    "- Celebrate your discoveries! üéâ\n",
    "\n",
    "**Ready to start your discovery journey? Let's begin with Phase 1!**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdc93e8",
   "metadata": {},
   "source": [
    "# üìä PHASE 1: Data Exploration (YOUR TURN!)\n",
    "\n",
    "## üéØ **Your Mission**\n",
    "Load the dataset and explore it step by step. Discover what we're working with!\n",
    "\n",
    "## üìù **Your Tasks**\n",
    "1. **Load the dataset** using pandas\n",
    "2. **Check the shape** - how many patients and features?\n",
    "3. **Look at the first few rows** - what does the data look like?\n",
    "4. **Check for missing values** - is the data clean?\n",
    "5. **Understand the target variable** - what's the caries prevalence?\n",
    "6. **Calculate basic statistics** - what are the ranges and means?\n",
    "\n",
    "## üí° **Hints**\n",
    "- Use `pd.read_csv()` to load the data\n",
    "- Use `.shape`, `.head()`, `.info()` to explore\n",
    "- Use `.isnull().sum()` to check missing values\n",
    "- Use `.describe()` for basic statistics\n",
    "- Use `.value_counts()` for the target variable\n",
    "\n",
    "## üéì **Learning Goal**\n",
    "Get familiar with your dataset and understand what you're working with!\n",
    "\n",
    "**Go ahead and write your code below! I'm here to help if you get stuck.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef6eb239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has 16708 rows and 22 columns\n",
      "   age  height(cm)  weight(kg)  waist(cm)  eyesight(left)  eyesight(right)  \\\n",
      "0   40         170          65       75.1             1.0              0.9   \n",
      "1   45         170          75       89.0             0.7              1.2   \n",
      "2   30         180          90       94.0             1.0              0.8   \n",
      "3   60         170          50       73.0             0.5              0.7   \n",
      "4   30         170          65       78.0             1.5              1.0   \n",
      "\n",
      "   hearing(left)  hearing(right)  systolic  relaxation  ...  triglyceride  \\\n",
      "0              1               1       120          70  ...           260   \n",
      "1              1               1       100          67  ...           345   \n",
      "2              1               1       115          72  ...           103   \n",
      "3              1               1       118          78  ...            70   \n",
      "4              1               1       110          70  ...           210   \n",
      "\n",
      "   HDL  LDL  hemoglobin  Urine protein  serum creatinine  AST  ALT  Gtp  \\\n",
      "0   41  132        15.7              1               0.8   24   26   32   \n",
      "1   49  140        15.7              1               1.1   26   28  138   \n",
      "2   53  103        13.5              1               1.0   19   29   30   \n",
      "3   65  108        14.1              1               1.3   31   28   33   \n",
      "4   45  103        14.7              1               0.8   21   21   19   \n",
      "\n",
      "   dental caries  \n",
      "0              0  \n",
      "1              0  \n",
      "2              0  \n",
      "3              0  \n",
      "4              0  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "age                    0\n",
      "height(cm)             0\n",
      "weight(kg)             0\n",
      "waist(cm)              0\n",
      "eyesight(left)         0\n",
      "eyesight(right)        0\n",
      "hearing(left)          0\n",
      "hearing(right)         0\n",
      "systolic               0\n",
      "relaxation             0\n",
      "fasting blood sugar    0\n",
      "Cholesterol            0\n",
      "triglyceride           0\n",
      "HDL                    0\n",
      "LDL                    0\n",
      "hemoglobin             0\n",
      "Urine protein          0\n",
      "serum creatinine       0\n",
      "AST                    0\n",
      "ALT                    0\n",
      "Gtp                    0\n",
      "dental caries          0\n",
      "dtype: int64\n",
      "dental caries\n",
      "0    13186\n",
      "1     3522\n",
      "Name: count, dtype: int64\n",
      "                age    height(cm)    weight(kg)     waist(cm)  eyesight(left)  \\\n",
      "count  16708.000000  16708.000000  16708.000000  16708.000000    16708.000000   \n",
      "mean      44.312006    164.555602     65.692782     82.009792        1.007182   \n",
      "std       12.089099      9.210712     12.639255      9.150549        0.458500   \n",
      "min       20.000000    135.000000     30.000000     53.000000        0.100000   \n",
      "25%       40.000000    160.000000     55.000000     76.000000        0.800000   \n",
      "50%       40.000000    165.000000     65.000000     82.000000        1.000000   \n",
      "75%       55.000000    170.000000     75.000000     88.000000        1.200000   \n",
      "max       85.000000    190.000000    125.000000    125.800000        9.900000   \n",
      "\n",
      "       eyesight(right)  hearing(left)  hearing(right)      systolic  \\\n",
      "count     16708.000000   16708.000000    16708.000000  16708.000000   \n",
      "mean          1.004351       1.026095        1.026035    121.537587   \n",
      "std           0.467140       0.159423        0.159245     13.751759   \n",
      "min           0.100000       1.000000        1.000000     79.000000   \n",
      "25%           0.800000       1.000000        1.000000    112.000000   \n",
      "50%           1.000000       1.000000        1.000000    120.000000   \n",
      "75%           1.200000       1.000000        1.000000    130.000000   \n",
      "max           9.900000       2.000000        2.000000    240.000000   \n",
      "\n",
      "         relaxation  ...  triglyceride           HDL           LDL  \\\n",
      "count  16708.000000  ...  16708.000000  16708.000000  16708.000000   \n",
      "mean      76.029148  ...    126.470254     57.283816    114.691525   \n",
      "std        9.727289  ...     71.259041     15.018255     35.948974   \n",
      "min       40.000000  ...     16.000000      4.000000      1.000000   \n",
      "25%       70.000000  ...     74.000000     47.000000     92.000000   \n",
      "50%       76.000000  ...    107.000000     55.000000    113.000000   \n",
      "75%       82.000000  ...    160.000000     66.000000    136.000000   \n",
      "max      140.000000  ...    405.000000    618.000000   1660.000000   \n",
      "\n",
      "         hemoglobin  Urine protein  serum creatinine           AST  \\\n",
      "count  16708.000000   16708.000000      16708.000000  16708.000000   \n",
      "mean      14.618692       1.088820          0.885055     26.147235   \n",
      "std        1.559794       0.411293          0.223621     19.769301   \n",
      "min        4.900000       1.000000          0.100000      6.000000   \n",
      "25%       13.600000       1.000000          0.800000     19.000000   \n",
      "50%       14.800000       1.000000          0.900000     23.000000   \n",
      "75%       15.800000       1.000000          1.000000     28.000000   \n",
      "max       20.900000       6.000000         10.300000   1311.000000   \n",
      "\n",
      "                ALT           Gtp  dental caries  \n",
      "count  16708.000000  16708.000000   16708.000000  \n",
      "mean      26.781362     40.062246       0.210797  \n",
      "std       30.085442     51.657330       0.407887  \n",
      "min        1.000000      1.000000       0.000000  \n",
      "25%       15.000000     17.000000       0.000000  \n",
      "50%       21.000000     25.000000       0.000000  \n",
      "75%       30.000000     43.000000       0.000000  \n",
      "max     2062.000000    999.000000       1.000000  \n",
      "\n",
      "[8 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# PHASE 1: DATA EXPLORATION - YOUR IMPLEMENTATION!\n",
    "# =============================================================================\n",
    "\n",
    "# Start by loading the dataset and exploring it step by step\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "# df = pd.read_csv('data/test_dataset.csv')\n",
    "df = pd.read_csv(\"data/test_dataset.csv\")\n",
    "\n",
    "# Step 2: Check the shape. The shape is the number of rows and columns in the dataset.\n",
    "# print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"The dataset has {df.shape[0]} rows and {df.shape[1]} columns\")\n",
    "\n",
    "# Step 3: Look at the first few rows\n",
    "# df.head()\n",
    "print(df.head())\n",
    "\n",
    "# Step 4: Check for missing values\n",
    "# df.isnull().sum()\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Step 5: Understand the target variable\n",
    "# df['dental caries'].value_counts()\n",
    "print(df['dental caries'].value_counts())\n",
    "\n",
    "# Step 6: Calculate basic statistics\n",
    "# df.describe()\n",
    "print(df.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb53c16f",
   "metadata": {},
   "source": [
    "# üîç PHASE 2: Feature Analysis (YOUR DISCOVERY!)\n",
    "\n",
    "## üéØ **Your Mission**\n",
    "Analyze which features are most correlated with dental caries. Discover the patterns!\n",
    "\n",
    "## üìù **Your Tasks**\n",
    "1. **Calculate correlations** between each feature and dental caries\n",
    "2. **Find the top 10 most correlated features** (positive and negative)\n",
    "3. **Explore liver function markers** (AST, ALT, GTP) - the novel research area!\n",
    "4. **Create some visualizations** to see the patterns\n",
    "5. **Think about feature engineering** - what new features could you create?\n",
    "\n",
    "## üí° **Hints**\n",
    "- Use `df.corr()['dental caries']` to get correlations\n",
    "- Use `.sort_values(key=abs, ascending=False)` to sort by absolute correlation\n",
    "- Try plotting correlations with `plt.barh()` or `sns.barplot()`\n",
    "- Explore the liver markers: `df[['AST', 'ALT', 'Gtp', 'dental caries']].corr()`\n",
    "- Think about ratios: BMI, AST/ALT ratio, HDL/LDL ratio\n",
    "\n",
    "## üéì **Learning Goal**\n",
    "Discover which features matter most for predicting dental caries!\n",
    "\n",
    "**What patterns do you find? Which features surprise you?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e8843b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The correlations are: \n",
      "age                   -0.121530\n",
      "height(cm)             0.070900\n",
      "weight(kg)             0.064669\n",
      "waist(cm)              0.032261\n",
      "eyesight(left)        -0.001695\n",
      "eyesight(right)        0.016955\n",
      "hearing(left)         -0.008199\n",
      "hearing(right)        -0.015386\n",
      "systolic               0.021690\n",
      "relaxation             0.022257\n",
      "fasting blood sugar    0.006787\n",
      "Cholesterol           -0.009584\n",
      "triglyceride           0.022543\n",
      "HDL                   -0.024717\n",
      "LDL                   -0.012207\n",
      "hemoglobin             0.065664\n",
      "Urine protein          0.002917\n",
      "serum creatinine       0.018398\n",
      "AST                    0.001480\n",
      "ALT                    0.017872\n",
      "Gtp                    0.031827\n",
      "dental caries          1.000000\n",
      "Name: dental caries, dtype: float64\n",
      "\n",
      "The top 10 correlations are:\n",
      "age            -0.121530\n",
      "height(cm)      0.070900\n",
      "hemoglobin      0.065664\n",
      "weight(kg)      0.064669\n",
      "waist(cm)       0.032261\n",
      "Gtp             0.031827\n",
      "HDL            -0.024717\n",
      "triglyceride    0.022543\n",
      "relaxation      0.022257\n",
      "systolic        0.021690\n",
      "Name: dental caries, dtype: float64\n",
      "The liver correlations are:                     AST       ALT       Gtp  dental caries\n",
      "AST            1.000000  0.844888  0.372310       0.001480\n",
      "ALT            0.844888  1.000000  0.350801       0.017872\n",
      "Gtp            0.372310  0.350801  1.000000       0.031827\n",
      "dental caries  0.001480  0.017872  0.031827       1.000000\n",
      "The number of patients with normal BMI: 10841\n",
      "The number of patients with normal AST_ALT_ratio: 13592\n",
      "The number of patients with normal HDL_LDL_ratio: 924\n",
      "The number of patients with caries is: 3522\n",
      "The number of patients without caries is: 13186\n",
      "The ratio of patients with caries to patients without caries is: 0.267\n",
      "Caries rate among patients with normal BMI: 0.202\n",
      "The ratio of patients with abnormal BMI and caries is: 0.380\n",
      "Caries rate among patients with normal AST_ALT_ratio: 0.215\n",
      "The ratio of patients with abnormal AST_ALT_ratio and caries is: 0.170\n",
      "Caries rate among patients with normal HDL_LDL_ratio: 0.211\n",
      "The ratio of patients with abnormal HDL_LDL_ratio and caries is: 0.945\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# PHASE 2: FEATURE ANALYSIS - YOUR IMPLEMENTATION!\n",
    "# =============================================================================\n",
    "\n",
    "# Analyze correlations and discover which features matter most\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Calculate correlations with dental caries\n",
    "# correlations = df.corr()['dental caries']\n",
    "correlations = df.corr()['dental caries']\n",
    "print(f\"The correlations are: \\n{correlations}\\n\")\n",
    "\n",
    "# Step 2: Remove the target variable (it will be 1.0) and find top correlations\n",
    "correlations_without_target = correlations.drop('dental caries')\n",
    "top_correlations = correlations_without_target.sort_values(key=abs, ascending=False)\n",
    "print(f\"The top 10 correlations are:\")\n",
    "print(top_correlations.head(10))\n",
    "\n",
    "# Step 3: Explore liver function markers specifically\n",
    "# liver_correlations = df[['AST', 'ALT', 'Gtp', 'dental caries']].corr()\n",
    "liver_correlations = df[['AST', 'ALT', 'Gtp', 'dental caries']].corr()\n",
    "print(f\"The liver correlations are: {liver_correlations}\")\n",
    "\n",
    "# Step 4: Create visualizations. figsize is the size of the figure.\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.barh(range(len(top_correlations)), top_correlations.values)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(range(len(top_correlations)), top_correlations.values)\n",
    "plt.xlabel('Correlation')\n",
    "plt.ylabel('Features')\n",
    "plt.title('Correlation of Features with Dental Caries')\n",
    "\n",
    "# Step 5: Think about feature engineering\n",
    "# BMI = weight / (height/100)**2\n",
    "# AST_ALT_ratio = AST / ALT\n",
    "# HDL_LDL_ratio = HDL / LDL\n",
    "BMI = df['weight(kg)'] / (df['height(cm)']/100)**2\n",
    "AST_ALT_ratio = df['AST'] / df['ALT']\n",
    "HDL_LDL_ratio = df['HDL'] / df['LDL']\n",
    "\n",
    "caries_patients = df[df['dental caries'] == 1]\n",
    "no_caries_patients = df[df['dental caries'] == 0]\n",
    "\n",
    "normal_BMI = BMI < 25\n",
    "normal_AST_ALT_ratio = AST_ALT_ratio < 1.5\n",
    "normal_HDL_LDL_ratio = HDL_LDL_ratio > 1\n",
    "\n",
    "# What patterns do you discover? Which features surprise you?\n",
    "# Count patients with normal values\n",
    "normal_BMI_count = normal_BMI.sum()\n",
    "normal_AST_ALT_count = normal_AST_ALT_ratio.sum()\n",
    "normal_HDL_LDL_count = normal_HDL_LDL_ratio.sum()\n",
    "\n",
    "print(f\"The number of patients with normal BMI: {normal_BMI_count}\")\n",
    "print(f\"The number of patients with normal AST_ALT_ratio: {normal_AST_ALT_count}\")\n",
    "print(f\"The number of patients with normal HDL_LDL_ratio: {normal_HDL_LDL_count}\")\n",
    "\n",
    "# Basic statistics about caries patients\n",
    "print(f\"The number of patients with caries is: {caries_patients.shape[0]}\")\n",
    "print(f\"The number of patients without caries is: {no_caries_patients.shape[0]}\")\n",
    "print(f\"The ratio of patients with caries to patients without caries is: {caries_patients.shape[0] / no_caries_patients.shape[0]:.3f}\")\n",
    "\n",
    "# Analyze caries rates among patients with normal values\n",
    "if normal_BMI_count > 0:\n",
    "    caries_with_normal_BMI = df[(normal_BMI) & (df['dental caries'] == 1)].shape[0]\n",
    "    caries_rate_normal_BMI = caries_with_normal_BMI / normal_BMI_count\n",
    "    print(f\"Caries rate among patients with normal BMI: {caries_rate_normal_BMI:.3f}\")\n",
    "    print(f\"The ratio of patients with abnormal BMI and caries is: {(caries_patients.shape[0] - caries_with_normal_BMI) / caries_patients.shape[0]:.3f}\")\n",
    "\n",
    "if normal_AST_ALT_count > 0:\n",
    "    caries_with_normal_AST_ALT = df[(normal_AST_ALT_ratio) & (df['dental caries'] == 1)].shape[0]\n",
    "    caries_rate_normal_AST_ALT = caries_with_normal_AST_ALT / normal_AST_ALT_count\n",
    "    print(f\"Caries rate among patients with normal AST_ALT_ratio: {caries_rate_normal_AST_ALT:.3f}\")\n",
    "    print(f\"The ratio of patients with abnormal AST_ALT_ratio and caries is: {(caries_patients.shape[0] - caries_with_normal_AST_ALT) / caries_patients.shape[0]:.3f}\")\n",
    "if normal_HDL_LDL_count > 0:\n",
    "    caries_with_normal_HDL_LDL = df[(normal_HDL_LDL_ratio) & (df['dental caries'] == 1)].shape[0]\n",
    "    caries_rate_normal_HDL_LDL = caries_with_normal_HDL_LDL / normal_HDL_LDL_count\n",
    "    print(f\"Caries rate among patients with normal HDL_LDL_ratio: {caries_rate_normal_HDL_LDL:.3f}\")\n",
    "    print(f\"The ratio of patients with abnormal HDL_LDL_ratio and caries is: {(caries_patients.shape[0] - caries_with_normal_HDL_LDL) / caries_patients.shape[0]:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e453143f",
   "metadata": {},
   "source": [
    "# ü§ñ PHASE 3: SVM Implementation (YOUR CODING!)\n",
    "\n",
    "## üéØ **Your Mission**\n",
    "Build your first SVM models and see how they perform! Experiment and learn!\n",
    "\n",
    "## üìù **Your Tasks**\n",
    "1. **Prepare your data** - separate features (X) from target (y)\n",
    "2. **Split the data** - train/test split (80/20 or 70/30)\n",
    "3. **Scale your features** - use StandardScaler\n",
    "4. **Build Linear SVM** - start with LinearSVC\n",
    "5. **Build RBF SVM** - try SVC with RBF kernel\n",
    "6. **Compare performance** - which works better?\n",
    "\n",
    "## üí° **Hints**\n",
    "- Use `train_test_split()` from sklearn\n",
    "- Use `StandardScaler()` to scale features\n",
    "- Try `LinearSVC()` and `SVC(kernel='rbf')`\n",
    "- Use `accuracy_score()` to evaluate\n",
    "- Try different hyperparameters: `C=1.0`, `C=10.0`\n",
    "\n",
    "## üéì **Learning Goal**\n",
    "Build your first SVM models and understand how they work!\n",
    "\n",
    "**What accuracy do you get? Which kernel works better?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e33e3991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM Accuracy: 0.7809694793536804\n",
      "RBF SVM Accuracy with C=1.0 and gamma=10: 0.805\n",
      "RBF SVM is better than Linear SVM\n",
      "Let's now try with diferent hyperparameters, C and gamma. \n",
      "\n",
      "RBF SVM Accuracy with C=0.01 and gamma=0.01: 0.781\n",
      "RBF SVM Accuracy with C=0.1 and gamma=0.01: 0.781\n",
      "RBF SVM Accuracy with C=1 and gamma=0.01: 0.781\n",
      "RBF SVM Accuracy with C=10 and gamma=0.01: 0.781\n",
      "RBF SVM Accuracy with C=100 and gamma=0.01: 0.777\n",
      "RBF SVM Accuracy with C=0.01 and gamma=0.1: 0.781\n",
      "RBF SVM Accuracy with C=0.1 and gamma=0.1: 0.781\n",
      "RBF SVM Accuracy with C=1 and gamma=0.1: 0.782\n",
      "RBF SVM Accuracy with C=10 and gamma=0.1: 0.765\n",
      "RBF SVM Accuracy with C=100 and gamma=0.1: 0.712\n",
      "RBF SVM Accuracy with C=0.01 and gamma=1: 0.781\n",
      "RBF SVM Accuracy with C=0.1 and gamma=1: 0.781\n",
      "RBF SVM Accuracy with C=1 and gamma=1: 0.804\n",
      "RBF SVM Accuracy with C=10 and gamma=1: 0.804\n",
      "RBF SVM Accuracy with C=100 and gamma=1: 0.804\n",
      "RBF SVM Accuracy with C=0.01 and gamma=10: 0.781\n",
      "RBF SVM Accuracy with C=0.1 and gamma=10: 0.781\n",
      "RBF SVM Accuracy with C=1 and gamma=10: 0.805\n",
      "RBF SVM Accuracy with C=10 and gamma=10: 0.805\n",
      "RBF SVM Accuracy with C=100 and gamma=10: 0.805\n",
      "RBF SVM Accuracy with C=0.01 and gamma=100: 0.781\n",
      "RBF SVM Accuracy with C=0.1 and gamma=100: 0.781\n",
      "RBF SVM Accuracy with C=1 and gamma=100: 0.805\n",
      "RBF SVM Accuracy with C=10 and gamma=100: 0.805\n",
      "RBF SVM Accuracy with C=100 and gamma=100: 0.805\n",
      "\n",
      "The best accuracy is:  0.8052064631956912 with C=100 and gamma=100\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# PHASE 3: SVM IMPLEMENTATION - YOUR IMPLEMENTATION!\n",
    "# =============================================================================\n",
    "\n",
    "# Build your first SVM models and see how they perform!\n",
    "\n",
    "# Step 1: Prepare your data. X x are the features we believe are important to predict the target variable.\n",
    "# We use the drop method to drop the target variable from the dataframe and assign the remaining columns to X.  \n",
    "# y is the target variable, which is the 'dental caries' column.\n",
    "# X = df.drop('dental caries', axis=1)  # Features\n",
    "# y = df['dental caries']  # Target\n",
    "X = df.drop('dental caries', axis=1)  # Features. Caries should not be included as a feature.\n",
    "y = df['dental caries']  # Target\n",
    "\n",
    "# Step 2: Split the data\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# First import the train_test_split function from the model_selection module and then split the data into training and testing sets.\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) # Test size is the proportion of the dataset to include in the test split. Random state is the seed used by the random number generator, this means that the same split will be produced every time the code is run.\n",
    "\n",
    "# Step 3: Scale your features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Step 4: Build Linear SVM\n",
    "from sklearn.svm import LinearSVC\n",
    "linear_svm = LinearSVC(random_state=42)\n",
    "linear_svm.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Step 5: Build RBF SVM\n",
    "from sklearn.svm import SVC\n",
    "rbf_svm = SVC(kernel='rbf', random_state=42, C=1.0, gamma= 10)\n",
    "rbf_svm.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Step 6: Evaluate performance\n",
    "from sklearn.metrics import accuracy_score\n",
    "linear_pred = linear_svm.predict(X_test_scaled)\n",
    "rbf_pred = rbf_svm.predict(X_test_scaled)\n",
    "\n",
    "accuracy_linear = accuracy_score(y_test, linear_pred)\n",
    "accuracy_rbf = accuracy_score(y_test, rbf_pred)\n",
    "\n",
    "print(f\"Linear SVM Accuracy: {accuracy_linear}\")\n",
    "print(f\"RBF SVM Accuracy with C=1.0 and gamma=10: {accuracy_rbf:.3f}\")\n",
    "# What accuracy do you get? Which kernel works better?\n",
    "if accuracy_linear > accuracy_rbf:\n",
    "    print(\"Linear SVM is better than RBF SVM\")\n",
    "else:\n",
    "    print(\"RBF SVM is better than Linear SVM\")\n",
    "print(\"Let's now try with diferent hyperparameters, C and gamma. \\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# We can now iterate though different values of C and gamma and find the best combination.\n",
    "gamma = [0.01, 0.1, 1, 10, 100]\n",
    "C = [0.01, 0.1, 1, 10, 100]\n",
    "accuracies = []\n",
    "for g in gamma:\n",
    "    for c in C:\n",
    "        rbf_svm = SVC(kernel='rbf', random_state=42, C=c, gamma=g)\n",
    "        rbf_svm.fit(X_train_scaled, y_train)\n",
    "        rbf_pred = rbf_svm.predict(X_test_scaled)\n",
    "        accuracy_rbf = accuracy_score(y_test, rbf_pred)\n",
    "        accuracies.append(accuracy_rbf)\n",
    "        print(f\"RBF SVM Accuracy with C={c} and gamma={g}: {accuracy_rbf:.3f}\")\n",
    "max_accuracy = max(accuracies)\n",
    "\n",
    "# üéØ YOUR DISCOVERY: Which kernel works better? What C value gives the best accuracy?\n",
    "print(\"\\nThe best accuracy is: \", max_accuracy,f\"with C={c} and gamma={g}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b80dde0",
   "metadata": {},
   "source": [
    "# üîç PHASE 4: Model Validation & Feature Selection (YOUR ANALYSIS!)\n",
    "\n",
    "## üéØ **Your Mission**\n",
    "Validate your best model and identify the most important features for dental caries prediction!\n",
    "\n",
    "## üìä **Results Analysis: C=100, gamma=100**\n",
    "\n",
    "**Our hyperparameter tuning revealed that C=100 and gamma=100 achieved the highest accuracy (80.5%). However, this raises important concerns:**\n",
    "\n",
    "### üö® **Why High Parameters Might Be Problematic:**\n",
    "\n",
    "**If C=100 and gamma=100 give the best results, why should we be concerned?**\n",
    "\n",
    "1. **Overfitting Risk**: \n",
    "   - **High C (100)**: The model has very low tolerance for misclassification\n",
    "   - **High gamma (100)**: The model is extremely sensitive to individual data points\n",
    "   - **Combined Effect**: This creates a very complex decision boundary that might memorize the training data rather than learning generalizable patterns\n",
    "\n",
    "2. **Real-World Performance**:\n",
    "   - **If the model overfits**: It will perform poorly on new, unseen patients\n",
    "   - **If the model is too complex**: It might not generalize to different populations or conditions\n",
    "   - **That's why validation is crucial**: We need to ensure our model works beyond our test set\n",
    "\n",
    "### üéØ **The Solution: Cross-Validation & Feature Selection**\n",
    "\n",
    "**If overfitting is a risk, why use cross-validation?**\n",
    "\n",
    "**Cross-Validation (CV)** is a technique that:\n",
    "- **Splits data multiple times**: Instead of one train/test split, it creates multiple splits\n",
    "- **Tests robustness**: Each split acts as a mini-test to see if performance is consistent\n",
    "- **Detects overfitting**: If performance varies wildly across splits, the model might be overfitting\n",
    "- **Provides confidence**: Gives us a range of performance (mean ¬± standard deviation)\n",
    "\n",
    "**If CV shows consistent high performance**: Our model is robust and generalizable\n",
    "**If CV shows high variance**: Our model might be overfitting and needs regularization\n",
    "\n",
    "### üî¨ **Feature Selection: Why Some Features Add Noise**\n",
    "\n",
    "**If we have 21 features, why might some be harmful?**\n",
    "\n",
    "1. **Irrelevant Features**:\n",
    "   - **If a feature has no relationship to dental caries**: It adds random noise\n",
    "   - **Example**: If \"hearing(left)\" has no correlation with caries, it confuses the model\n",
    "   - **That's why feature selection matters**: Remove noise to improve performance\n",
    "\n",
    "2. **Redundant Features**:\n",
    "   - **If two features measure the same thing**: They provide duplicate information\n",
    "   - **Example**: \"eyesight(left)\" and \"eyesight(right)\" might be highly correlated\n",
    "   - **That's why correlation analysis helps**: Identify which features provide unique information\n",
    "\n",
    "3. **Curse of Dimensionality**:\n",
    "   - **If we have too many features relative to samples**: The model struggles to find patterns\n",
    "   - **With 16,708 patients and 21 features**: We're probably okay, but fewer features might be better\n",
    "   - **That's why dimensionality reduction works**: Focus on the most informative features\n",
    "\n",
    "### üéì **Your Next Steps:**\n",
    "\n",
    "**Phase 4A: Cross-Validation Analysis**\n",
    "- Test your best model (C=100, gamma=100) with 5-fold cross-validation\n",
    "- Compare with more conservative parameters (C=1, gamma=1)\n",
    "- **If CV shows high variance**: The model is overfitting\n",
    "- **If CV shows consistent performance**: The model is robust\n",
    "\n",
    "**Phase 4B: Feature Importance Analysis**\n",
    "- Identify which features contribute most to predictions\n",
    "- Compare with your earlier correlation analysis\n",
    "- **If important features match correlations**: Your analysis was correct\n",
    "- **If new features emerge**: You've discovered hidden patterns\n",
    "\n",
    "**Phase 4C: Optimized Model**\n",
    "- Build a new SVM using only the most important features\n",
    "- Compare performance with the full-feature model\n",
    "- **If performance improves**: Feature selection worked\n",
    "- **If performance decreases**: All features are valuable\n",
    "\n",
    "## üéØ **Learning Goals**\n",
    "- Understand why high hyperparameters can be problematic\n",
    "- Learn cross-validation as a validation technique\n",
    "- Master feature selection for better model performance\n",
    "- Build confidence in model interpretation\n",
    "\n",
    "**Ready to validate your model and discover the most important features?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "440174d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model (C=100, gamma=100) CV Scores: [0.80441286 0.80658436 0.80845492 0.80583614 0.80882903]\n",
      "Best Model CV Mean: 0.8068234633097926 ¬± 0.0016448049027952192\n",
      "\n",
      "Conservative Model (C=1, gamma=1) CV Scores: [0.80403889 0.80621025 0.80845492 0.80508792 0.80882903]\n",
      "Conservative Model CV Mean: 0.806524202103027 ¬± 0.0018643041721086728\n",
      "‚úÖ Low variance - model appears robust\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# PHASE 4A: CROSS-VALIDATION ANALYSIS (CORRECTED VERSION)\n",
    "# =============================================================================\n",
    "\n",
    "# Step 1: Import cross-validation tools\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Step 2: Test your best model (C=100, gamma=100) with 5-fold CV\n",
    "best_model = SVC(kernel='rbf', C=100, gamma=100, random_state=42)\n",
    "# FIXED: Use scaled data for cross-validation\n",
    "cv_scores_best = cross_val_score(best_model, X_train_scaled, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# Step 3: Test conservative model (C=1, gamma=1) for comparison\n",
    "conservative_model = SVC(kernel='rbf', C=1, gamma=1, random_state=42)\n",
    "# FIXED: Use scaled data for cross-validation\n",
    "cv_scores_conservative = cross_val_score(conservative_model, X_train_scaled, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# Step 4: Compare CV results\n",
    "print(\"Best Model (C=100, gamma=100) CV Scores:\", cv_scores_best)\n",
    "print(\"Best Model CV Mean:\", cv_scores_best.mean(), \"¬±\", cv_scores_best.std())\n",
    "print(\"\\nConservative Model (C=1, gamma=1) CV Scores:\", cv_scores_conservative)\n",
    "print(\"Conservative Model CV Mean:\", cv_scores_conservative.mean(), \"¬±\", cv_scores_conservative.std())\n",
    "\n",
    "# Step 5: Analyze variance (high std = potential overfitting)\n",
    "if cv_scores_best.std() > 0.02:\n",
    "    print(\"‚ö†Ô∏è  High variance detected - model might be overfitting!\")\n",
    "else:\n",
    "    print(\"‚úÖ Low variance - model appears robust\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e5a11af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç TOP 10 MOST IMPORTANT FEATURES:\n",
      "         feature  importance       std\n",
      "9     relaxation    0.023220  0.000359\n",
      "3      waist(cm)    0.023130  0.000683\n",
      "15    hemoglobin    0.023010  0.000620\n",
      "8       systolic    0.022801  0.000639\n",
      "13           HDL    0.022681  0.000397\n",
      "14           LDL    0.022561  0.000486\n",
      "11   Cholesterol    0.022531  0.000502\n",
      "12  triglyceride    0.022412  0.000738\n",
      "18           AST    0.021574  0.000785\n",
      "2     weight(kg)    0.021544  0.000974\n",
      "\n",
      "üìä COMPARISON WITH CORRELATION ANALYSIS:\n",
      "Do the important features match your correlation findings?\n",
      "The top 10 previous important features before cross-validation are: \n",
      "age            -0.121530\n",
      "height(cm)      0.070900\n",
      "hemoglobin      0.065664\n",
      "weight(kg)      0.064669\n",
      "waist(cm)       0.032261\n",
      "Gtp             0.031827\n",
      "HDL            -0.024717\n",
      "triglyceride    0.022543\n",
      "relaxation      0.022257\n",
      "systolic        0.021690\n",
      "Name: dental caries, dtype: float64\n",
      "The top 10 new important features after cross-validation are: \n",
      "         feature  importance       std\n",
      "9     relaxation    0.023220  0.000359\n",
      "3      waist(cm)    0.023130  0.000683\n",
      "15    hemoglobin    0.023010  0.000620\n",
      "8       systolic    0.022801  0.000639\n",
      "13           HDL    0.022681  0.000397\n",
      "14           LDL    0.022561  0.000486\n",
      "11   Cholesterol    0.022531  0.000502\n",
      "12  triglyceride    0.022412  0.000738\n",
      "18           AST    0.021574  0.000785\n",
      "2     weight(kg)    0.021544  0.000974\n",
      "The top 10 important features do not match the correlation findings.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# PHASE 4B: FEATURE IMPORTANCE ANALYSIS (CORRECTED VERSION)\n",
    "# =============================================================================\n",
    "\n",
    "# Step 6: Train your best model on full training set (FIXED: Use scaled data)\n",
    "best_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Step 7: Get feature importance (FIXED: Use scaled data for permutation importance)\n",
    "from sklearn.inspection import permutation_importance\n",
    "perm_importance = permutation_importance(best_model, X_test_scaled, y_test, n_repeats=10, random_state=42)\n",
    "\n",
    "# Step 8: Create feature importance dataframe\n",
    "feature_names = X.columns\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': perm_importance.importances_mean,\n",
    "    'std': perm_importance.importances_std\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "# Step 9: Display top 10 most important features\n",
    "print(\"üîç TOP 10 MOST IMPORTANT FEATURES:\")\n",
    "print(importance_df.head(10))\n",
    "\n",
    "# Step 10: Compare with your earlier correlation analysis\n",
    "print(\"\\nüìä COMPARISON WITH CORRELATION ANALYSIS:\")\n",
    "print(\"Do the important features match your correlation findings?\")\n",
    "print(f\"The top 10 previous important features before cross-validation are: \\n{top_correlations.head(10)}\")\n",
    "print(f\"The top 10 new important features after cross-validation are: \\n{importance_df.head(10)}\")\n",
    "\n",
    "if top_correlations.head(10).equals(importance_df.head(10)):\n",
    "    print(\"The top 10 important features match the correlation findings.\")\n",
    "else:\n",
    "    print(\"The top 10 important features do not match the correlation findings.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "13f818ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ MODEL COMPARISON:\n",
      "Full-feature model accuracy: 80.52%\n",
      "Optimized model accuracy: 80.52%\n",
      "Features used: 7 vs 21\n",
      "\n",
      "Optimized model CV: 0.807 ¬± 0.002\n",
      "\n",
      "\n",
      "üîç Using top 1 features:\n",
      "Features: relaxation\n",
      "Optimized model accuracy with 1 features: 78.04%\n",
      "Optimized model CV: 0.791 ¬± 0.000\n",
      "Features used: 1 vs 21\n",
      "\n",
      "\n",
      "\n",
      "üîç Using top 2 features:\n",
      "Features: relaxation, waist(cm)\n",
      "Optimized model accuracy with 2 features: 76.06%\n",
      "Optimized model CV: 0.758 ¬± 0.007\n",
      "Features used: 2 vs 21\n",
      "\n",
      "\n",
      "\n",
      "üîç Using top 3 features:\n",
      "Features: relaxation, waist(cm), hemoglobin\n",
      "Optimized model accuracy with 3 features: 73.82%\n",
      "Optimized model CV: 0.740 ¬± 0.008\n",
      "Features used: 3 vs 21\n",
      "\n",
      "\n",
      "\n",
      "üîç Using top 4 features:\n",
      "Features: relaxation, waist(cm), hemoglobin, systolic\n",
      "Optimized model accuracy with 4 features: 79.20%\n",
      "Optimized model CV: 0.792 ¬± 0.003\n",
      "Features used: 4 vs 21\n",
      "\n",
      "\n",
      "\n",
      "üîç Using top 5 features:\n",
      "Features: relaxation, waist(cm), hemoglobin, systolic, HDL\n",
      "Optimized model accuracy with 5 features: 80.49%\n",
      "Optimized model CV: 0.806 ¬± 0.002\n",
      "Features used: 5 vs 21\n",
      "\n",
      "\n",
      "\n",
      "üîç Using top 6 features:\n",
      "Features: relaxation, waist(cm), hemoglobin, systolic, HDL, LDL\n",
      "Optimized model accuracy with 6 features: 80.49%\n",
      "Optimized model CV: 0.807 ¬± 0.002\n",
      "Features used: 6 vs 21\n",
      "\n",
      "\n",
      "\n",
      "üîç Using top 7 features:\n",
      "Features: relaxation, waist(cm), hemoglobin, systolic, HDL, LDL, Cholesterol\n",
      "Optimized model accuracy with 7 features: 80.52%\n",
      "Optimized model CV: 0.807 ¬± 0.002\n",
      "Features used: 7 vs 21\n",
      "\n",
      "\n",
      "\n",
      "üîç Using top 8 features:\n",
      "Features: relaxation, waist(cm), hemoglobin, systolic, HDL, LDL, Cholesterol, triglyceride\n",
      "Optimized model accuracy with 8 features: 80.52%\n",
      "Optimized model CV: 0.807 ¬± 0.002\n",
      "Features used: 8 vs 21\n",
      "\n",
      "\n",
      "\n",
      "üîç Using top 9 features:\n",
      "Features: relaxation, waist(cm), hemoglobin, systolic, HDL, LDL, Cholesterol, triglyceride, AST\n",
      "Optimized model accuracy with 9 features: 80.52%\n",
      "Optimized model CV: 0.807 ¬± 0.002\n",
      "Features used: 9 vs 21\n",
      "\n",
      "\n",
      "\n",
      "üîç Using top 10 features:\n",
      "Features: relaxation, waist(cm), hemoglobin, systolic, HDL, LDL, Cholesterol, triglyceride, AST, weight(kg)\n",
      "Optimized model accuracy with 10 features: 80.52%\n",
      "Optimized model CV: 0.807 ¬± 0.002\n",
      "Features used: 10 vs 21\n",
      "\n",
      "\n",
      "\n",
      "üîç Using top 11 features:\n",
      "Features: relaxation, waist(cm), hemoglobin, systolic, HDL, LDL, Cholesterol, triglyceride, AST, weight(kg), serum creatinine\n",
      "Optimized model accuracy with 11 features: 80.52%\n",
      "Optimized model CV: 0.807 ¬± 0.002\n",
      "Features used: 11 vs 21\n",
      "\n",
      "\n",
      "\n",
      "üîç Using top 12 features:\n",
      "Features: relaxation, waist(cm), hemoglobin, systolic, HDL, LDL, Cholesterol, triglyceride, AST, weight(kg), serum creatinine, fasting blood sugar\n",
      "Optimized model accuracy with 12 features: 80.52%\n",
      "Optimized model CV: 0.807 ¬± 0.002\n",
      "Features used: 12 vs 21\n",
      "\n",
      "\n",
      "\n",
      "üîç Using top 13 features:\n",
      "Features: relaxation, waist(cm), hemoglobin, systolic, HDL, LDL, Cholesterol, triglyceride, AST, weight(kg), serum creatinine, fasting blood sugar, age\n",
      "Optimized model accuracy with 13 features: 80.52%\n",
      "Optimized model CV: 0.807 ¬± 0.002\n",
      "Features used: 13 vs 21\n",
      "\n",
      "\n",
      "\n",
      "üîç Using top 14 features:\n",
      "Features: relaxation, waist(cm), hemoglobin, systolic, HDL, LDL, Cholesterol, triglyceride, AST, weight(kg), serum creatinine, fasting blood sugar, age, eyesight(left)\n",
      "Optimized model accuracy with 14 features: 80.52%\n",
      "Optimized model CV: 0.807 ¬± 0.002\n",
      "Features used: 14 vs 21\n",
      "\n",
      "\n",
      "\n",
      "üîç Using top 15 features:\n",
      "Features: relaxation, waist(cm), hemoglobin, systolic, HDL, LDL, Cholesterol, triglyceride, AST, weight(kg), serum creatinine, fasting blood sugar, age, eyesight(left), eyesight(right)\n",
      "Optimized model accuracy with 15 features: 80.52%\n",
      "Optimized model CV: 0.807 ¬± 0.002\n",
      "Features used: 15 vs 21\n",
      "\n",
      "\n",
      "\n",
      "üîç Using top 16 features:\n",
      "Features: relaxation, waist(cm), hemoglobin, systolic, HDL, LDL, Cholesterol, triglyceride, AST, weight(kg), serum creatinine, fasting blood sugar, age, eyesight(left), eyesight(right), height(cm)\n",
      "Optimized model accuracy with 16 features: 80.52%\n",
      "Optimized model CV: 0.807 ¬± 0.002\n",
      "Features used: 16 vs 21\n",
      "\n",
      "\n",
      "\n",
      "üîç Using top 17 features:\n",
      "Features: relaxation, waist(cm), hemoglobin, systolic, HDL, LDL, Cholesterol, triglyceride, AST, weight(kg), serum creatinine, fasting blood sugar, age, eyesight(left), eyesight(right), height(cm), Gtp\n",
      "Optimized model accuracy with 17 features: 80.52%\n",
      "Optimized model CV: 0.807 ¬± 0.002\n",
      "Features used: 17 vs 21\n",
      "\n",
      "\n",
      "\n",
      "üîç Using top 18 features:\n",
      "Features: relaxation, waist(cm), hemoglobin, systolic, HDL, LDL, Cholesterol, triglyceride, AST, weight(kg), serum creatinine, fasting blood sugar, age, eyesight(left), eyesight(right), height(cm), Gtp, ALT\n",
      "Optimized model accuracy with 18 features: 80.52%\n",
      "Optimized model CV: 0.807 ¬± 0.002\n",
      "Features used: 18 vs 21\n",
      "\n",
      "\n",
      "\n",
      "üîç Using top 19 features:\n",
      "Features: relaxation, waist(cm), hemoglobin, systolic, HDL, LDL, Cholesterol, triglyceride, AST, weight(kg), serum creatinine, fasting blood sugar, age, eyesight(left), eyesight(right), height(cm), Gtp, ALT, Urine protein\n",
      "Optimized model accuracy with 19 features: 80.52%\n",
      "Optimized model CV: 0.807 ¬± 0.002\n",
      "Features used: 19 vs 21\n",
      "\n",
      "\n",
      "\n",
      "üîç Using top 20 features:\n",
      "Features: relaxation, waist(cm), hemoglobin, systolic, HDL, LDL, Cholesterol, triglyceride, AST, weight(kg), serum creatinine, fasting blood sugar, age, eyesight(left), eyesight(right), height(cm), Gtp, ALT, Urine protein, hearing(right)\n",
      "Optimized model accuracy with 20 features: 80.52%\n",
      "Optimized model CV: 0.807 ¬± 0.002\n",
      "Features used: 20 vs 21\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# PHASE 4C: OPTIMIZED MODEL WITH SELECTED FEATURES (CORRECTED VERSION)\n",
    "# =============================================================================\n",
    "\n",
    "# Step 11: Select top N features (try different numbers: 5, 10, 15)\n",
    "features_to_use = 7\n",
    "top_features = importance_df.head(features_to_use)['feature'].tolist()\n",
    "\n",
    "# FIXED: Use scaled data for feature selection\n",
    "# Get feature indices for the selected features\n",
    "feature_indices = [X.columns.get_loc(feature) for feature in top_features]\n",
    "X_train_selected = X_train_scaled[:, feature_indices]\n",
    "X_test_selected = X_test_scaled[:, feature_indices]\n",
    "\n",
    "# Step 12: Build optimized model with selected features\n",
    "optimized_model = SVC(kernel='rbf', C=100, gamma=100, random_state=42)\n",
    "optimized_model.fit(X_train_selected, y_train)\n",
    "\n",
    "# Step 13: Test optimized model performance\n",
    "optimized_pred = optimized_model.predict(X_test_selected)\n",
    "optimized_accuracy = accuracy_score(y_test, optimized_pred)\n",
    "\n",
    "# Step 14: Compare with full-feature model\n",
    "print(f\"\\nüéØ MODEL COMPARISON:\")\n",
    "print(f\"Full-feature model accuracy: {max_accuracy * 100:.2f}%\")\n",
    "print(f\"Optimized model accuracy: {optimized_accuracy * 100:.2f}%\")\n",
    "print(f\"Features used: {features_to_use} vs 21\\n\")\n",
    "\n",
    "# Step 15: Cross-validate the optimized model (FIXED: Use scaled data)\n",
    "cv_scores_optimized = cross_val_score(optimized_model, X_train_selected, y_train, cv=5, scoring='accuracy')\n",
    "print(f\"Optimized model CV: {cv_scores_optimized.mean():.3f} ¬± {cv_scores_optimized.std():.3f}\\n\")\n",
    "\n",
    "# Let's use a loop to try different number of features to use as top features and see how the accuracy changes.\n",
    "for features_to_use in range(1, 21):\n",
    "    top_features = importance_df.head(features_to_use)['feature'].tolist()\n",
    "    print(f\"\\nüîç Using top {features_to_use} features:\")\n",
    "    print(f\"Features: {', '.join(top_features)}\")\n",
    "    \n",
    "    # FIXED: Use scaled data for feature selection\n",
    "    feature_indices = [X.columns.get_loc(feature) for feature in top_features]\n",
    "    X_train_selected = X_train_scaled[:, feature_indices]\n",
    "    X_test_selected = X_test_scaled[:, feature_indices]\n",
    "    \n",
    "    optimized_model = SVC(kernel='rbf', C=100, gamma=100, random_state=42)\n",
    "    optimized_model.fit(X_train_selected, y_train)\n",
    "    optimized_pred = optimized_model.predict(X_test_selected)\n",
    "    optimized_accuracy = accuracy_score(y_test, optimized_pred)\n",
    "    print(f\"Optimized model accuracy with {features_to_use} features: {optimized_accuracy * 100:.2f}%\")\n",
    "    \n",
    "    # FIXED: Use scaled data for cross-validation\n",
    "    cv_scores_optimized = cross_val_score(optimized_model, X_train_selected, y_train, cv=5, scoring='accuracy')\n",
    "    print(f\"Optimized model CV: {cv_scores_optimized.mean():.3f} ¬± {cv_scores_optimized.std():.3f}\")\n",
    "    print(f\"Features used: {features_to_use} vs 21\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43918330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà FINAL ANALYSIS (CORRECTED VERSION):\n",
      "1. Cross-validation shows:\n",
      "The optimized model has better performance\n",
      "2. Most important features before cross-validation are: \n",
      "age          -0.121530\n",
      "height(cm)    0.070900\n",
      "hemoglobin    0.065664\n",
      "weight(kg)    0.064669\n",
      "waist(cm)     0.032261\n",
      "Name: dental caries, dtype: float64\n",
      "3. Most important features after cross-validation are: \n",
      "['relaxation', 'waist(cm)', 'hemoglobin', 'systolic', 'HDL']\n",
      "4. Feature selection impact:\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# PHASE 4D: FINAL ANALYSIS & CONCLUSIONS (CORRECTED VERSION)\n",
    "# =============================================================================\n",
    "\n",
    "# Step 16: Analyze your results\n",
    "print(f\"\\nüìà FINAL ANALYSIS (CORRECTED VERSION):\")\n",
    "print(f\"1. Cross-validation shows:\")\n",
    "if cv_scores_optimized.mean() >= max_accuracy:\n",
    "    print(\"The optimized model has better performance\")\n",
    "else:\n",
    "    print(\"The optimized model has worse performance\")\n",
    "print(f\"2. Most important features before cross-validation are: \\n{top_correlations[:5]}\")\n",
    "print(f\"3. Most important features after cross-validation are: \\n{top_features[:5]}\")\n",
    "print(f\"4. Feature selection impact:\")\n",
    "\n",
    "# Find the best performing model from the loop\n",
    "best_accuracy = 0\n",
    "best_features_count = 0\n",
    "best_features_list = []\n",
    "\n",
    "for features_to_use in range(1, 21):\n",
    "    top_features_temp = importance_df.head(features_to_use)['feature'].tolist()\n",
    "    feature_indices_temp = [X.columns.get_loc(feature) for feature in top_features_temp]\n",
    "    X_train_selected_temp = X_train_scaled[:, feature_indices_temp]\n",
    "    X_test_selected_temp = X_test_scaled[:, feature_indices_temp]\n",
    "    \n",
    "    optimized_model_temp = SVC(kernel='rbf', C=100, gamma=100, random_state=42)\n",
    "    optimized_model_temp.fit(X_train_selected_temp, y_train)\n",
    "    optimized_pred_temp = optimized_model_temp.predict(X_test_selected_temp)\n",
    "    optimized_accuracy_temp = accuracy_score(y_test, optimized_pred_temp)\n",
    "    \n",
    "    if optimized_accuracy_temp > best_accuracy:\n",
    "        best_accuracy = optimized_accuracy_temp\n",
    "        best_features_count = features_to_use\n",
    "        best_features_list = top_features_temp\n",
    "\n",
    "print(f\"The best model accuracy is: {best_accuracy:.4f} with {best_features_count} features: {best_features_list}\\n\")\n",
    "print(f\"5. Overfitting risk:\")\n",
    "if cv_scores_optimized.std() > 0.02:\n",
    "    print(\"High\")\n",
    "else:\n",
    "    print(\"Low\")\n",
    "\n",
    "# Step 17: Draw your conclusions\n",
    "print(f\"\\nüéì YOUR CONCLUSIONS (CORRECTED VERSION):\\n\")\n",
    "print(f\"- Which features are most predictive of dental caries?\")\n",
    "print(f\"The features with which we obtained the highest accuracy are: {best_features_list}\\n\")\n",
    "print(f\"- Is the liver-oral health connection confirmed?\")\n",
    "liver_features = [\"AST\", \"ALT\", \"Gtp\"]\n",
    "if any(feature in best_features_list for feature in liver_features):\n",
    "    print(\"Yes, the liver-oral health connection is confirmed\\n\")\n",
    "else:\n",
    "    print(\"No, the liver-oral health connection is not confirmed\\n\")\n",
    "print(f\"- How reliable is your accuracy?\")\n",
    "print(f\"The accuracy of the optimized model is: {best_accuracy * 100:.2f}%\\n\")\n",
    "print(f\"- What would you recommend for clinical use?\")\n",
    "print(f\"I would recommend using the optimized model with the features: {best_features_list} for clinical use\")\n",
    "\n",
    "print(f\"\\nüîß CORRECTIONS MADE:\")\n",
    "print(f\"- Used scaled data (X_train_scaled, X_test_scaled) for all cross-validation\")\n",
    "print(f\"- Used scaled data for permutation importance analysis\")\n",
    "print(f\"- Used scaled data for feature selection and model training\")\n",
    "print(f\"- This ensures consistent preprocessing throughout the analysis\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937b9ddb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d839c62e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model (C=100, gamma=100) CV Scores: [0.80441286 0.80658436 0.80845492 0.80583614 0.80882903]\n",
      "Best Model CV Mean: 0.8068234633097926 ¬± 0.0016448049027952192\n",
      "\n",
      "Conservative Model (C=1, gamma=1) CV Scores: [0.80441286 0.80658436 0.80845492 0.80583614 0.80882903]\n",
      "Conservative Model CV Mean: 0.8068234633097926 ¬± 0.0016448049027952192\n",
      "‚úÖ Low variance - model appears robust\n"
     ]
    }
   ],
   "source": [
    "# üîç PHASE 4: Model Validation & Feature Selection - YOUR IMPLEMENTATION!\n",
    "\n",
    "# =============================================================================\n",
    "# PHASE 4A: CROSS-VALIDATION ANALYSIS\n",
    "# =============================================================================\n",
    "\n",
    "# Step 1: Import cross-validation tools\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Step 2: Test your best model (C=100, gamma=100) with 5-fold CV\n",
    "best_model = SVC(kernel='rbf', C=100, gamma=100, random_state=42)\n",
    "# By using cross_val_score, we can test the model with different folds (meaning different splits of the data) and see how it performs.\n",
    "cv_scores_best = cross_val_score(best_model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# Step 3: Test conservative model (C=1, gamma=1) for comparison\n",
    "conservative_model = SVC(kernel='rbf', C=1, gamma=1, random_state=42)\n",
    "cv_scores_conservative = cross_val_score(conservative_model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# Step 4: Compare CV results\n",
    "print(\"Best Model (C=100, gamma=100) CV Scores:\", cv_scores_best)\n",
    "print(\"Best Model CV Mean:\", cv_scores_best.mean(), \"¬±\", cv_scores_best.std())\n",
    "print(\"\\nConservative Model (C=1, gamma=1) CV Scores:\", cv_scores_conservative)\n",
    "print(\"Conservative Model CV Mean:\", cv_scores_conservative.mean(), \"¬±\", cv_scores_conservative.std())\n",
    "\n",
    "# Step 5: Analyze variance (high std = potential overfitting)\n",
    "if cv_scores_best.std() > 0.02:\n",
    "    print(\"‚ö†Ô∏è  High variance detected - model might be overfitting!\")\n",
    "else:\n",
    "    print(\"‚úÖ Low variance - model appears robust\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68b2d95b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç TOP 10 MOST IMPORTANT FEATURES:\n",
      "                feature  importance       std\n",
      "12         triglyceride    0.024087  0.000150\n",
      "14                  LDL    0.023968  0.000282\n",
      "11          Cholesterol    0.023938  0.000189\n",
      "20                  Gtp    0.023908  0.000209\n",
      "3             waist(cm)    0.023818  0.000448\n",
      "13                  HDL    0.023758  0.000486\n",
      "8              systolic    0.023579  0.000293\n",
      "15           hemoglobin    0.023549  0.000584\n",
      "10  fasting blood sugar    0.023519  0.000486\n",
      "19                  ALT    0.023429  0.000301\n",
      "\n",
      "üìä COMPARISON WITH CORRELATION ANALYSIS:\n",
      "Do the important features match your correlation findings?\n",
      "The top 10 previous important features before cross-validation are: \n",
      "age            -0.121530\n",
      "height(cm)      0.070900\n",
      "hemoglobin      0.065664\n",
      "weight(kg)      0.064669\n",
      "waist(cm)       0.032261\n",
      "Gtp             0.031827\n",
      "HDL            -0.024717\n",
      "triglyceride    0.022543\n",
      "relaxation      0.022257\n",
      "systolic        0.021690\n",
      "Name: dental caries, dtype: float64\n",
      "The top 10 new important features after cross-validation are: \n",
      "                feature  importance       std\n",
      "12         triglyceride    0.024087  0.000150\n",
      "14                  LDL    0.023968  0.000282\n",
      "11          Cholesterol    0.023938  0.000189\n",
      "20                  Gtp    0.023908  0.000209\n",
      "3             waist(cm)    0.023818  0.000448\n",
      "13                  HDL    0.023758  0.000486\n",
      "8              systolic    0.023579  0.000293\n",
      "15           hemoglobin    0.023549  0.000584\n",
      "10  fasting blood sugar    0.023519  0.000486\n",
      "19                  ALT    0.023429  0.000301\n",
      "The top 10 important features do not match the correlation findings.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# PHASE 4B: FEATURE IMPORTANCE ANALYSIS\n",
    "# =============================================================================\n",
    "\n",
    "# Step 6: Train your best model on full training set\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 7: Get feature importance (for RBF kernel, we'll use permutation importance). By using permutation_importance, we can see how important each feature is to the model.\n",
    "from sklearn.inspection import permutation_importance\n",
    "perm_importance = permutation_importance(best_model, X_test, y_test, n_repeats=10, random_state=42)\n",
    "\n",
    "# print(f\"Permutation Importance: {perm_importance}\")\n",
    "\n",
    "# Step 8: Create feature importance dataframe\n",
    "feature_names = X.columns\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': perm_importance.importances_mean,\n",
    "    'std': perm_importance.importances_std\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "# Step 9: Display top 10 most important features\n",
    "print(\"üîç TOP 10 MOST IMPORTANT FEATURES:\")\n",
    "print(importance_df.head(10))\n",
    "\n",
    "# Step 10: Compare with your earlier correlation analysis\n",
    "print(\"\\nüìä COMPARISON WITH CORRELATION ANALYSIS:\")\n",
    "print(\"Do the important features match your correlation findings?\")\n",
    "print(f\"The top 10 previous important features before cross-validation are: \\n{top_correlations.head(10)}\")\n",
    "print(f\"The top 10 new important features after cross-validation are: \\n{importance_df.head(10)}\")\n",
    "\n",
    "if top_correlations.head(10).equals(importance_df.head(10)):\n",
    "    print(\"The top 10 important features match the correlation findings.\")\n",
    "else:\n",
    "    print(\"The top 10 important features do not match the correlation findings.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdaa9721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ MODEL COMPARISON:\n",
      "Full-feature model accuracy: 80.52%\n",
      "Optimized model accuracy: 80.52%\n",
      "Features used: 7 vs 21\n",
      "\n",
      "Optimized model CV: 0.807 ¬± 0.002\n",
      "\n",
      "\n",
      "üîç Using top 1 features:\n",
      "Features: triglyceride\n",
      "Optimized model accuracy with 1 features: 77.74%\n",
      "Optimized model CV: 0.789 ¬± 0.001\n",
      "Features used: 1 vs 21\n",
      "\n",
      "\n",
      "\n",
      "üîç Using top 2 features:\n",
      "Features: triglyceride, LDL\n",
      "Optimized model accuracy with 2 features: 76.39%\n",
      "Optimized model CV: 0.764 ¬± 0.005\n",
      "Features used: 2 vs 21\n",
      "\n",
      "\n",
      "\n",
      "üîç Using top 3 features:\n",
      "Features: triglyceride, LDL, Cholesterol\n",
      "Optimized model accuracy with 3 features: 80.34%\n",
      "Optimized model CV: 0.805 ¬± 0.001\n",
      "Features used: 3 vs 21\n",
      "\n",
      "\n",
      "\n",
      "üîç Using top 4 features:\n",
      "Features: triglyceride, LDL, Cholesterol, Gtp\n",
      "Optimized model accuracy with 4 features: 80.55%\n",
      "Optimized model CV: 0.807 ¬± 0.002\n",
      "Features used: 4 vs 21\n",
      "\n",
      "\n",
      "\n",
      "üîç Using top 5 features:\n",
      "Features: triglyceride, LDL, Cholesterol, Gtp, waist(cm)\n",
      "Optimized model accuracy with 5 features: 80.52%\n",
      "Optimized model CV: 0.807 ¬± 0.002\n",
      "Features used: 5 vs 21\n",
      "\n",
      "\n",
      "\n",
      "üîç Using top 6 features:\n",
      "Features: triglyceride, LDL, Cholesterol, Gtp, waist(cm), HDL\n",
      "Optimized model accuracy with 6 features: 80.52%\n",
      "Optimized model CV: 0.807 ¬± 0.002\n",
      "Features used: 6 vs 21\n",
      "\n",
      "\n",
      "\n",
      "üîç Using top 7 features:\n",
      "Features: triglyceride, LDL, Cholesterol, Gtp, waist(cm), HDL, systolic\n",
      "Optimized model accuracy with 7 features: 80.52%\n",
      "Optimized model CV: 0.807 ¬± 0.002\n",
      "Features used: 7 vs 21\n",
      "\n",
      "\n",
      "\n",
      "üîç Using top 8 features:\n",
      "Features: triglyceride, LDL, Cholesterol, Gtp, waist(cm), HDL, systolic, hemoglobin\n",
      "Optimized model accuracy with 8 features: 80.52%\n",
      "Optimized model CV: 0.807 ¬± 0.002\n",
      "Features used: 8 vs 21\n",
      "\n",
      "\n",
      "\n",
      "üîç Using top 9 features:\n",
      "Features: triglyceride, LDL, Cholesterol, Gtp, waist(cm), HDL, systolic, hemoglobin, fasting blood sugar\n",
      "Optimized model accuracy with 9 features: 80.52%\n",
      "Optimized model CV: 0.807 ¬± 0.002\n",
      "Features used: 9 vs 21\n",
      "\n",
      "\n",
      "\n",
      "üîç Using top 10 features:\n",
      "Features: triglyceride, LDL, Cholesterol, Gtp, waist(cm), HDL, systolic, hemoglobin, fasting blood sugar, ALT\n",
      "Optimized model accuracy with 10 features: 80.52%\n",
      "Optimized model CV: 0.807 ¬± 0.002\n",
      "Features used: 10 vs 21\n",
      "\n",
      "\n",
      "\n",
      "üîç Using top 11 features:\n",
      "Features: triglyceride, LDL, Cholesterol, Gtp, waist(cm), HDL, systolic, hemoglobin, fasting blood sugar, ALT, AST\n",
      "Optimized model accuracy with 11 features: 80.52%\n",
      "Optimized model CV: 0.807 ¬± 0.002\n",
      "Features used: 11 vs 21\n",
      "\n",
      "\n",
      "\n",
      "üîç Using top 12 features:\n",
      "Features: triglyceride, LDL, Cholesterol, Gtp, waist(cm), HDL, systolic, hemoglobin, fasting blood sugar, ALT, AST, relaxation\n",
      "Optimized model accuracy with 12 features: 80.52%\n",
      "Optimized model CV: 0.807 ¬± 0.002\n",
      "Features used: 12 vs 21\n",
      "\n",
      "\n",
      "\n",
      "üîç Using top 13 features:\n",
      "Features: triglyceride, LDL, Cholesterol, Gtp, waist(cm), HDL, systolic, hemoglobin, fasting blood sugar, ALT, AST, relaxation, weight(kg)\n",
      "Optimized model accuracy with 13 features: 80.52%\n",
      "Optimized model CV: 0.807 ¬± 0.002\n",
      "Features used: 13 vs 21\n",
      "\n",
      "\n",
      "\n",
      "üîç Using top 14 features:\n",
      "Features: triglyceride, LDL, Cholesterol, Gtp, waist(cm), HDL, systolic, hemoglobin, fasting blood sugar, ALT, AST, relaxation, weight(kg), age\n",
      "Optimized model accuracy with 14 features: 80.52%\n",
      "Optimized model CV: 0.807 ¬± 0.002\n",
      "Features used: 14 vs 21\n",
      "\n",
      "\n",
      "\n",
      "üîç Using top 15 features:\n",
      "Features: triglyceride, LDL, Cholesterol, Gtp, waist(cm), HDL, systolic, hemoglobin, fasting blood sugar, ALT, AST, relaxation, weight(kg), age, eyesight(left)\n",
      "Optimized model accuracy with 15 features: 80.52%\n",
      "Optimized model CV: 0.807 ¬± 0.002\n",
      "Features used: 15 vs 21\n",
      "\n",
      "\n",
      "\n",
      "üîç Using top 16 features:\n",
      "Features: triglyceride, LDL, Cholesterol, Gtp, waist(cm), HDL, systolic, hemoglobin, fasting blood sugar, ALT, AST, relaxation, weight(kg), age, eyesight(left), eyesight(right)\n",
      "Optimized model accuracy with 16 features: 80.52%\n",
      "Optimized model CV: 0.807 ¬± 0.002\n",
      "Features used: 16 vs 21\n",
      "\n",
      "\n",
      "\n",
      "üîç Using top 17 features:\n",
      "Features: triglyceride, LDL, Cholesterol, Gtp, waist(cm), HDL, systolic, hemoglobin, fasting blood sugar, ALT, AST, relaxation, weight(kg), age, eyesight(left), eyesight(right), height(cm)\n",
      "Optimized model accuracy with 17 features: 80.52%\n",
      "Optimized model CV: 0.807 ¬± 0.002\n",
      "Features used: 17 vs 21\n",
      "\n",
      "\n",
      "\n",
      "üîç Using top 18 features:\n",
      "Features: triglyceride, LDL, Cholesterol, Gtp, waist(cm), HDL, systolic, hemoglobin, fasting blood sugar, ALT, AST, relaxation, weight(kg), age, eyesight(left), eyesight(right), height(cm), serum creatinine\n",
      "Optimized model accuracy with 18 features: 80.52%\n",
      "Optimized model CV: 0.807 ¬± 0.002\n",
      "Features used: 18 vs 21\n",
      "\n",
      "\n",
      "\n",
      "üîç Using top 19 features:\n",
      "Features: triglyceride, LDL, Cholesterol, Gtp, waist(cm), HDL, systolic, hemoglobin, fasting blood sugar, ALT, AST, relaxation, weight(kg), age, eyesight(left), eyesight(right), height(cm), serum creatinine, Urine protein\n",
      "Optimized model accuracy with 19 features: 80.52%\n",
      "Optimized model CV: 0.807 ¬± 0.002\n",
      "Features used: 19 vs 21\n",
      "\n",
      "\n",
      "\n",
      "üîç Using top 20 features:\n",
      "Features: triglyceride, LDL, Cholesterol, Gtp, waist(cm), HDL, systolic, hemoglobin, fasting blood sugar, ALT, AST, relaxation, weight(kg), age, eyesight(left), eyesight(right), height(cm), serum creatinine, Urine protein, hearing(right)\n",
      "Optimized model accuracy with 20 features: 80.52%\n",
      "Optimized model CV: 0.807 ¬± 0.002\n",
      "Features used: 20 vs 21\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# PHASE 4C: OPTIMIZED MODEL WITH SELECTED FEATURES\n",
    "# =============================================================================\n",
    "\n",
    "# Step 11: Select top N features (try different numbers: 5, 10, 15)\n",
    "features_to_use = 7\n",
    "top_features = importance_df.head(features_to_use)['feature'].tolist()  # Try 10 features\n",
    "X_train_selected = X_train[top_features]\n",
    "X_test_selected = X_test[top_features]\n",
    "\n",
    "# Step 12: Build optimized model with selected features\n",
    "optimized_model = SVC(kernel='rbf', C=100, gamma=100, random_state=42)\n",
    "optimized_model.fit(X_train_selected, y_train)\n",
    "\n",
    "# Step 13: Test optimized model performance\n",
    "optimized_pred = optimized_model.predict(X_test_selected)\n",
    "optimized_accuracy = accuracy_score(y_test, optimized_pred)\n",
    "\n",
    "# Step 14: Compare with full-feature model\n",
    "print(f\"\\nüéØ MODEL COMPARISON:\")\n",
    "print(f\"Full-feature model accuracy: {max_accuracy * 100:.2f}%\")\n",
    "print(f\"Optimized model accuracy: {optimized_accuracy * 100:.2f}%\")\n",
    "print(f\"Features used: {features_to_use} vs 21\\n\")\n",
    "\n",
    "# Step 15: Cross-validate the optimized model\n",
    "cv_scores_optimized = cross_val_score(optimized_model, X_train_selected, y_train, cv=5, scoring='accuracy')\n",
    "print(f\"Optimized model CV: {cv_scores_optimized.mean():.3f} ¬± {cv_scores_optimized.std():.3f}\\n\")\n",
    "\n",
    "# Let's use a loop to try different number of features to use as top features and see how the accuracy changes.\n",
    "for features_to_use in range(1, 21):\n",
    "    top_features = importance_df.head(features_to_use)['feature'].tolist()\n",
    "    print(f\"\\nüîç Using top {features_to_use} features:\")\n",
    "    print(f\"Features: {', '.join(top_features)}\")\n",
    "    X_train_selected = X_train[top_features]\n",
    "    X_test_selected = X_test[top_features]\n",
    "    optimized_model = SVC(kernel='rbf', C=100, gamma=100, random_state=42)\n",
    "    optimized_model.fit(X_train_selected, y_train)\n",
    "    optimized_pred = optimized_model.predict(X_test_selected)\n",
    "    optimized_accuracy = accuracy_score(y_test, optimized_pred)\n",
    "    print(f\"Optimized model accuracy with {features_to_use} features: {optimized_accuracy * 100:.2f}%\")\n",
    "    cv_scores_optimized = cross_val_score(optimized_model, X_train_selected, y_train, cv=5, scoring='accuracy')\n",
    "    print(f\"Optimized model CV: {cv_scores_optimized.mean():.3f} ¬± {cv_scores_optimized.std():.3f}\")\n",
    "    print(f\"Features used: {features_to_use} vs 21\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "# üéØ YOUR DISCOVERY: Which features are most predictive of dental caries? \n",
    "if optimized_accuracy.max() > max_accuracy:\n",
    "    print(f\"The optimized model has better performance with the features: {top_features[optimized_accuracy.argmax()]}\")\n",
    "else:\n",
    "    print(f\"The full-feature model has better performance with the features: {top_features[max_accuracy.argmax()]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9dbc2d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà FINAL ANALYSIS:\n",
      "1. Cross-validation shows:\n",
      "The optimized model has better performance\n",
      "2. Most important features before cross-validation are: \n",
      "age          -0.121530\n",
      "height(cm)    0.070900\n",
      "hemoglobin    0.065664\n",
      "weight(kg)    0.064669\n",
      "waist(cm)     0.032261\n",
      "Name: dental caries, dtype: float64\n",
      "3. Most important features after cross-validation are: \n",
      "['triglyceride', 'LDL', 'Cholesterol', 'Gtp', 'waist(cm)']\n",
      "4. Feature selection impact:\n",
      "The best model accuracy is: 0.8055 with 4 features: ['triglyceride', 'LDL', 'Cholesterol', 'Gtp']\n",
      "\n",
      "5. Overfitting risk:\n",
      "Low\n",
      "\n",
      "üéì YOUR CONCLUSIONS:\n",
      "\n",
      "- Which features are most predictive of dental caries?\n",
      "The features with which we obtained the highest accuracy are: ['triglyceride', 'LDL', 'Cholesterol', 'Gtp']\n",
      "\n",
      "- Is the liver-oral health connection confirmed?\n",
      "Yes, the liver-oral health connection is confirmed\n",
      "\n",
      "- How reliable is your 80.5% accuracy?\n",
      "The accuracy of the optimized model is: 80.52%\n",
      "\n",
      "- What would you recommend for clinical use?\n",
      "I would recommend using the optimized model with the features: ['triglyceride', 'LDL', 'Cholesterol', 'Gtp'] for clinical use\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# PHASE 4D: FINAL ANALYSIS & CONCLUSIONS\n",
    "# =============================================================================\n",
    "\n",
    "# Step 16: Analyze your results\n",
    "print(f\"\\nüìà FINAL ANALYSIS:\")\n",
    "print(f\"1. Cross-validation shows:\")\n",
    "if cv_scores_optimized.mean() >= max_accuracy:\n",
    "    print(\"The optimized model has better performance\")\n",
    "else:\n",
    "    print(\"The optimized model has worse performance\")\n",
    "print(f\"2. Most important features before cross-validation are: \\n{top_correlations[:5]}\")\n",
    "print(f\"3. Most important features after cross-validation are: \\n{top_features[:5]}\")\n",
    "print(f\"4. Feature selection impact:\")\n",
    "\n",
    "# Find the best performing model from the loop\n",
    "best_accuracy = 0\n",
    "best_features_count = 0\n",
    "for features_to_use in range(1, 21):\n",
    "    top_features_temp = importance_df.head(features_to_use)['feature'].tolist()\n",
    "    X_train_selected_temp = X_train[top_features_temp]\n",
    "    X_test_selected_temp = X_test[top_features_temp]\n",
    "    optimized_model_temp = SVC(kernel='rbf', C=100, gamma=100, random_state=42)\n",
    "    optimized_model_temp.fit(X_train_selected_temp, y_train)\n",
    "    optimized_pred_temp = optimized_model_temp.predict(X_test_selected_temp)\n",
    "    optimized_accuracy_temp = accuracy_score(y_test, optimized_pred_temp)\n",
    "    \n",
    "    if optimized_accuracy_temp > best_accuracy:\n",
    "        best_accuracy = optimized_accuracy_temp\n",
    "        best_features_count = features_to_use\n",
    "\n",
    "model_stall = best_accuracy\n",
    "features_stall = importance_df.head(best_features_count)['feature'].tolist()\n",
    "print(f\"The best model accuracy is: {model_stall:.4f} with {best_features_count} features: {features_stall}\\n\")\n",
    "print(f\"5. Overfitting risk:\")\n",
    "if cv_scores_optimized.std() > 0.02:\n",
    "    print(\"High\")\n",
    "else:\n",
    "    print(\"Low\")\n",
    "\n",
    "# Step 17: Draw your conclusions\n",
    "print(f\"\\nüéì YOUR CONCLUSIONS:\\n\")\n",
    "print(f\"- Which features are most predictive of dental caries?\")\n",
    "print(f\"The features with which we obtained the highest accuracy are: {features_stall}\\n\")\n",
    "print(f\"- Is the liver-oral health connection confirmed?\")\n",
    "liver_features = [\"AST\", \"ALT\", \"Gtp\"]\n",
    "if any(feature in features_stall for feature in liver_features):\n",
    "    print(\"Yes, the liver-oral health connection is confirmed\\n\")\n",
    "else:\n",
    "    print(\"No, the liver-oral health connection is not confirmed\\n\")\n",
    "print(f\"- How reliable is your 80.5% accuracy?\")\n",
    "print(f\"The accuracy of the optimized model is: {optimized_accuracy * 100:.2f}%\\n\")\n",
    "print(f\"- What would you recommend for clinical use?\")\n",
    "print(f\"I would recommend using the optimized model with the features: {features_stall} for clinical use\")\n",
    "\n",
    "# üéØ YOUR MISSION: Implement these steps and discover the answers!\n",
    "# üí° HINTS: Start with Phase 4A, then move to 4B, then 4C\n",
    "# üöÄ GOAL: Build confidence in your model and identify the key features!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Periodontal Disease Project",
   "language": "python",
   "name": "periodontal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
